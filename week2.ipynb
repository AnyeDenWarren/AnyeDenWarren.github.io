{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "We start by preparing the tools(packages) and maps(datasets) needed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#import packages\r\n",
    "import os\r\n",
    "import pandas as pd # for handling data\r\n",
    "import numpy as np #numerical cla\r\n",
    "import matplotlib.pyplot as plt #visualise data\r\n",
    "import seaborn as sns #visualise data\r\n",
    "from datetime import datetime\r\n",
    "import sklearn\r\n",
    "from sklearn.datasets import load_boston"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#define working diretory\r\n",
    "os.chdir('E:\\Summer Semester\\Summer break and Internship\\Data Glacier internship files\\week2\\Data')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import data set, joing and merging(https://datacarpentry.org/python-ecology-lesson/05-merging-data/)\r\n",
    "Cab_Data = pd.read_csv('Cab_Data.csv', keep_default_na=False, na_values= [\"\"]) # assign empty values in our CSV to NaN(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv) \r\n",
    "Cab_Data\r\n",
    "City = pd.read_csv('City.csv')\r\n",
    "Transaction_ID = pd.read_csv('Transaction_ID.csv')\r\n",
    "Customer_ID = pd.read_csv('Customer_ID.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data information\r\n",
    "Transaction_ID.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#top 5 observation\r\n",
    "City.head()\r\n",
    "Cab_Data.head()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#deleting a column/variable\r\n",
    "City.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# concatenate cab data and transaction id\r\n",
    "Transaction_ID = Transaction_ID.head(359392)\r\n",
    "cab_concat_trans = pd.concat([Cab_Data,Transaction_ID], axis = 1) #concatenating or stacking horizonatlly or vertically\r\n",
    "cab_concat_trans"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#joining our data\r\n",
    "City.columns\r\n",
    "cab_concat_trans.columns\r\n",
    "\r\n",
    "merged_inner = pd.merge(left = cab_concat_trans, right = City)\r\n",
    "merged_inner\r\n",
    "merged_inner = pd.merge(left = merged_inner,right = Customer_ID)\r\n",
    "merged_inner\r\n",
    "merged_inner.drop_duplicates(subset= 'Transaction ID',keep= 'first', inplace= False) # removes duplicate rows \r\n",
    "merged_inner = merged_inner.loc[:,~merged_inner.columns.duplicated()] # removes duplicate columns\r\n",
    "Data = merged_inner\r\n",
    "minimum = Data[\"Date of Travel\"].min()\r\n",
    "index = Data[\"Date of Travel\"].idxmin()\r\n",
    "Data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#converting unix to datetime\r\n",
    "#Data[\"Date of Travel\"]=  pd.to_datetime (Data[\"Date of Travel\"], unit= 'h')\r\n",
    "Data[\"Date of Travel\"]=pd.to_datetime(pd.to_numeric(Data[\"Date of Travel\"],errors='coerce'),errors='coerce',origin='1900-01-28',unit='D')\r\n",
    "Data.head(6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "source": [
    "# dereived features\r\n",
    "Data = Data.replace(',','', regex=True) # removes commas\r\n",
    "\r\n",
    "Data['Users'] = pd.to_numeric(Data['Users'], errors='coerce') # string to numeric\r\n",
    "Data['Population'] = pd.to_numeric(Data['Population'], errors='coerce')\r\n",
    "\r\n",
    "Data['profitPerPerson'] = Data['Price Charged'] - Data['Cost of Trip']\r\n",
    "Data['Total Profit'] = Data['profitPerPerson']*Data['Users']\r\n",
    "Data['Yearly Income'] = Data['Income (USD/Month)']*12\r\n",
    "Data['PricePerKM'] = Data['Price Charged']/Data['KM Travelled']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save data\r\n",
    "\r\n",
    "Data.to_csv(r'E:\\Summer Semester\\Summer break and Internship\\Data Glacier internship files\\week2\\Data\\Data.csv', index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read data\r\n",
    "Data = pd.read_csv('Data.csv', keep_default_na=False, na_values= [\"\"])\r\n",
    "Data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#outlier detection and removal using boxplot\r\n",
    "ax = sns.boxplot(x =Data['Total Profit'] )\r\n",
    "index1 = np.where(Data['Total Profit']>0.7e8)\r\n",
    "index1[0]\r\n",
    "Data.drop(index1[0], inplace = True)\r\n",
    "#Data.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#outlier removal using IQR interquatile range\r\n",
    "Q1 = np.percentile(Data['Total Profit'], 25,\r\n",
    " interpolation = 'midpoint')\r\n",
    " \r\n",
    "Q3 = np.percentile(Data['Total Profit'], 75,\r\n",
    " interpolation = 'midpoint')\r\n",
    "IQR = Q3 - Q1\r\n",
    " \r\n",
    "print(\"Old Shape: \", Data.shape)\r\n",
    " \r\n",
    "# Upper bound\r\n",
    "upper = np.where(Data['Total Profit'] >= (Q3+1.5*IQR))\r\n",
    "# Lower bound\r\n",
    "lower = np.where(Data['Total Profit'] <= (Q1-1.5*IQR))\r\n",
    " \r\n",
    "''' Removing the Outliers '''\r\n",
    "Data.drop(upper[0], inplace = True)\r\n",
    "Data.drop(lower[0], inplace = True)\r\n",
    " \r\n",
    "print(\"New Shape: \", Data.shape)\r\n",
    "\r\n",
    "# To add a new cell, type '# %%'\r\n",
    "# To add a new markdown cell, type '# %% [markdown]'\r\n",
    "# %% [markdown]\r\n",
    "# We start by preparing the tools(packages) and maps(datasets) needed\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# To add a new cell, type '# %%'\r\n",
    "# To add a new markdown cell, type '# %% [markdown]'\r\n",
    "# %% [markdown]\r\n",
    "# We start by preparing the tools(packages) and maps(datasets) needed\r\n",
    "\r\n",
    "# %%\r\n",
    "#import packages\r\n",
    "import os\r\n",
    "import pandas as pd # for handling data\r\n",
    "import numpy as np #numerical cla\r\n",
    "import matplotlib.pyplot as plt #visualise data\r\n",
    "import seaborn as sns #visualise data\r\n",
    "from datetime import datetime\r\n",
    "import sklearn\r\n",
    "from sklearn.datasets import load_boston\r\n",
    "from collections import Counter # for looping\r\n",
    "import matplotlib.ticker as ticker\r\n",
    "from scipy import stats\r\n",
    "from statsmodels.stats import weightstats as stests\r\n",
    "import matplotlib.patches as mpatches\r\n",
    "\r\n",
    "# %%\r\n",
    "#define working diretory\r\n",
    "os.chdir('E:\\Summer Semester\\Summer break and Internship\\Data Glacier internship files\\week2\\Data')\r\n",
    "\r\n",
    "\r\n",
    "# %%\r\n",
    "#import data set, joing and merging(https://datacarpentry.org/python-ecology-lesson/05-merging-data/)\r\n",
    "Cab_Data = pd.read_csv('Cab_Data.csv', keep_default_na=False, na_values= [\"\"]) # assign empty values in our CSV to NaN(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv) \r\n",
    "Cab_Data\r\n",
    "City = pd.read_csv('City.csv')\r\n",
    "Transaction_ID = pd.read_csv('Transaction_ID.csv')\r\n",
    "Customer_ID = pd.read_csv('Customer_ID.csv')\r\n",
    "\r\n",
    "# %%\r\n",
    "# data information #top 5 observation\r\n",
    "Transaction_ID.head()\r\n",
    "City.head()\r\n",
    "Cab_Data.head()\r\n",
    "\r\n",
    "# %%\r\n",
    "# concatenate cab data and transaction id\r\n",
    "Transaction_ID = Transaction_ID.head(359392)\r\n",
    "cab_concat_trans = pd.concat([Cab_Data,Transaction_ID], axis = 1) #concatenating or stacking horizonatlly or vertically\r\n",
    "cab_concat_trans\r\n",
    "\r\n",
    "#%%\r\n",
    "#joining our data\r\n",
    "City.columns\r\n",
    "cab_concat_trans.columns\r\n",
    "merged_inner = pd.merge(left = cab_concat_trans, right = City)\r\n",
    "merged_inner\r\n",
    "merged_inner = pd.merge(left = merged_inner,right = Customer_ID)\r\n",
    "merged_inner\r\n",
    "merged_inner.drop_duplicates(subset= 'Transaction ID',keep= 'first', inplace= False) # removes duplicate rows \r\n",
    "merged_inner = merged_inner.loc[:,~merged_inner.columns.duplicated()] # removes duplicate columns\r\n",
    "Data = merged_inner\r\n",
    "minimum = Data[\"Date of Travel\"].min()\r\n",
    "index = Data[\"Date of Travel\"].idxmin()\r\n",
    "Data\r\n",
    "\r\n",
    "# %%\r\n",
    "#converting unix to datetime\r\n",
    "#Data[\"Date of Travel\"]=  pd.to_datetime (Data[\"Date of Travel\"], unit= 'h')\r\n",
    "Data[\"Date of Travel\"]=pd.to_datetime(pd.to_numeric(Data[\"Date of Travel\"],errors='coerce'),errors='coerce',origin='1900-01-28',unit='D')\r\n",
    "Data.head(6)\r\n",
    "\r\n",
    "# %%\r\n",
    "# dereived features\r\n",
    "Data = Data.replace(',','', regex=True) # removes commas\r\n",
    "Data['Users'] = pd.to_numeric(Data['Users'], errors='coerce') # string to numeric\r\n",
    "Data['Population'] = pd.to_numeric(Data['Population'], errors='coerce')\r\n",
    "Data['profitPerPerson'] = Data['Price Charged'] - Data['Cost of Trip']\r\n",
    "Data['Total Profit'] = Data['profitPerPerson']*Data['Users']\r\n",
    "Data['Yearly Income'] = Data['Income (USD/Month)']*12\r\n",
    "Data['PricePerKM'] = Data['Price Charged']/Data['KM Travelled']\r\n",
    "# %%\r\n",
    "# save data\r\n",
    "Data.to_csv(r'E:\\Summer Semester\\Summer break and Internship\\Data Glacier internship files\\week2\\Data\\Data.csv', index = False)\r\n",
    "\r\n",
    "# %%\r\n",
    "# read data\r\n",
    "Data = pd.read_csv('Data.csv', keep_default_na=False, na_values= [\"\"])\r\n",
    "Data\r\n",
    "# %%\r\n",
    "#outlier detection and removal using boxplot\r\n",
    "ax = sns.boxplot(x =Data['Price Charged'] )\r\n",
    "index1 = np.where(Data['Price Charged']>1100)\r\n",
    "Data.drop(index1[0], inplace = True)\r\n",
    "#Data.info()\r\n",
    "# %%\r\n",
    "Data.reset_index(drop = True, inplace= True)\r\n",
    "Data.head(30)\r\n",
    "Data\r\n",
    "#%%droping Nan\r\n",
    "Data = Data.dropna().reset_index(drop=True)\r\n",
    "#%%\r\n",
    "#outlier detection and removal using boxplot/drop\r\n",
    "index1 = np.where(Data['PricePerKM']>32)\r\n",
    "Data.drop(index1[0], inplace = True)\r\n",
    "ax = sns.boxplot(x =Data['PricePerKM'] )\r\n",
    "\r\n",
    "# %%\r\n",
    "#outlier removal using IQR interquatile range\r\n",
    "ax = sns.boxplot(x =Data['Total Profit'] )\r\n",
    "Q1 = np.percentile(Data['Total Profit'], 30,\r\n",
    " interpolation = 'midpoint')\r\n",
    " \r\n",
    "Q3 = np.percentile(Data['Total Profit'], 75,\r\n",
    "interpolation = 'midpoint')\r\n",
    "IQR = Q3 - Q1\r\n",
    "print(\"Old Shape: \", Data.shape)\r\n",
    "# Upper bound\r\n",
    "upper = np.where(Data['Total Profit'] >= (Q3+1.5*IQR))\r\n",
    "# Lower bound\r\n",
    "lower = np.where(Data['Total Profit'] <= (Q1-1.5*IQR))\r\n",
    " \r\n",
    "''' Removing the Outliers '''\r\n",
    "Data.drop(upper[0], inplace = True)\r\n",
    "Data.drop(lower[0], inplace = True)\r\n",
    " \r\n",
    "print(\"New Shape: \", Data.shape)\r\n",
    "\r\n",
    "#%%\r\n",
    "#hypothesis testing\r\n",
    "\r\n",
    "YellowCabUser= []\r\n",
    "Data_numerical = Data.select_dtypes(exclude ='object')\r\n",
    "Data_categorical = Data.select_dtypes(include='object')\r\n",
    "Data.info()\r\n",
    "#%% selecting yellow and pink Cabs using filtering method\r\n",
    "Yellowcab = []\r\n",
    "Pinkcab = []\r\n",
    "YellowCabUser = 0\r\n",
    "PinkCabuser = 0\r\n",
    "Yellowcab = Data[Data.Company == \"Yellow Cab\"]\r\n",
    "#user = np.zeros((len(Yellowcab,2)))\r\n",
    "u = Yellowcab.head(82291)\r\n",
    "start = datetime.datetime()\r\n",
    "\r\n",
    "Pinkcab = Data[Data.Company == \"Pink Cab\"]\r\n",
    "#%%\r\n",
    "# reset date  and set date as index\r\n",
    "Yellowcab = Yellowcab.sort_values('Date of Travel').reset_index(drop=True).set_index('Date of Travel')\r\n",
    "Pinkcab = Pinkcab.sort_values('Date of Travel').reset_index(drop=True).set_index('Date of Travel')\r\n",
    "# seperate categorical and numerical varaibles\r\n",
    "Yellowcab_numerical =  Yellowcab.select_dtypes(exclude ='object')\r\n",
    "Pinkcab_numerical =  Pinkcab.select_dtypes(exclude ='object')\r\n",
    "\r\n",
    "#plot users\r\n",
    "\r\n",
    "Yellowcab['Users'].plot()\r\n",
    "Pinkcab['Users'].plot()\r\n",
    "Yellowcab.iloc[0:500].plot(y='Users',label = 'Yellow cab users')\r\n",
    "Pinkcab.iloc[0:500].plot(y='Users',label = 'Pink cab users')\r\n",
    "\r\n",
    "\r\n",
    "plt.figure(figsize=(10,5))\r\n",
    "plt.plot(Yellowcab.iloc[0:700]['Users'].sum(), label = 'Yellow cab users')\r\n",
    "plt.plot(Pinkcab.iloc[0:700]['Users'], label = 'Pink cab users')\r\n",
    "plt.xticks(rotation=70)\r\n",
    "plt.title(\"Yellow Cab and Pink Cab users\")\r\n",
    "plt.xlabel(\"Date\")\r\n",
    "plt.ylabel('Number of users')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "#%% Z test for hypotesis testing\r\n",
    "ztest ,pval1 = stests.ztest(Yellowcab.iloc[0:700]['Users'], x2=Pinkcab.iloc[0:700]['Users'], value=0,alternative='two-sided')\r\n",
    "print(float(pval1))\r\n",
    "if pval1<0.05:\r\n",
    "    print(\"reject null hypothesis\")\r\n",
    "else:\r\n",
    "    print(\"accept null hypothesis\")\r\n",
    "\r\n",
    "#%% corellation\r\n",
    "print('Users: mean=%.3f stdv=%.3f' % (np.mean(Data['Users']), np.std(Data['Users'])))\r\n",
    "print('Total Profit: mean=%.3f stdv=%.3f' % (np.mean(Data['Total Profit']), np.std(Data['Total Profit'])))\r\n",
    "# plot\r\n",
    "plt.scatter(Data.iloc[0:550]['Users'], Data.iloc[0:550]['profitPerPerson'])\r\n",
    "plt.title('Users vs profitPerPerson')\r\n",
    "plt.xlabel('users')\r\n",
    "plt.ylabel('profitPerPerson')\r\n",
    "\r\n",
    "#calculating covariance\r\n",
    "covariance = np.cov(Data['Users'], Data['Total Profit'])\r\n",
    "print(covariance)\r\n",
    "\r\n",
    "#profit\r\n",
    "ax = Pinkcab.plot(x=\"Total Profit\", y=Yellowcab.iloc[0:82291]['Users'], kind=\"bar\")\r\n",
    "\r\n",
    "newDF = Yellowcab.append(Pinkcab)\r\n",
    "newDF= pd.concat([Yellowcab, Pinkcab], ignore_index=False) # new index for date\r\n",
    "\r\n",
    "newDF = newDF.sort_values('Date of Travel')\r\n",
    "newDF = newDF.set_index('Date of Travel')\r\n",
    "\r\n",
    "sns.catplot(x='Date of Travel', y='Total Profit', hue='Company', data=Data.iloc[0:2000])\r\n",
    "plt.xticks(rotation=70)\r\n",
    "plt.title('Total Profit vs Date of Travel')\r\n",
    "Yprofit  = Yellowcab['Total Profit'].sum()\r\n",
    "Pprofit  = Pinkcab['Total Profit'].sum()\r\n",
    "print(Yprofit)\r\n",
    "print(Pprofit)\r\n",
    "\r\n",
    "#income\r\n",
    "sns.set(style=\"darkgrid\") #plot style\r\n",
    "plt.figure(figsize=(14, 14)) #set figure size\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "total = Data.groupby(Data['Date of Travel'].map(lambda x: x.year))['Yearly Income'].sum().reset_index()\r\n",
    "#Pink cab = orange\r\n",
    "bar1 = sns.barplot(x=\"Date of Travel\",  y=\"Yearly Income\",data=total,color=\"red\")\r\n",
    "#yellow cab\r\n",
    "ycom = Data[Data.Company=='Pink Cab']\r\n",
    "ycom = ycom.groupby(ycom['Date of Travel'].map(lambda x: x.year))['Yearly Income'].sum().reset_index()\r\n",
    "bar2 = sns.barplot(x=\"Date of Travel\", y=\"Yearly Income\", data=ycom, estimator=sum, ci=None,  color='darkblue')\r\n",
    "\r\n",
    "# add legend\r\n",
    "top_bar = mpatches.Patch(color='red', label='Pink Cab Income')\r\n",
    "bottom_bar = mpatches.Patch(color='darkblue', label='Yellow Cab Income')\r\n",
    "plt.legend(handles=[top_bar, bottom_bar])\r\n",
    "plt.xticks(rotation=0)\r\n",
    "plt.title('Date of Travel vs Yearly Income')\r\n",
    "# show the graph\r\n",
    "plt.show()\r\n",
    "\r\n",
    "ygen = Yellowcab.groupby(Yellowcab['Gender'])['profitPerPerson'].sum().reset_index()\r\n",
    "pgen = Pinkcab.groupby(Pinkcab['Gender'])['profitPerPerson'].sum().reset_index()\r\n",
    "bar1 = sns.barplot(x=\"Gender\",  y=\"profitPerPerson\",data=ygen,color=\"red\")\r\n",
    "plt.title('Profit Gender wise for Yellow cab company')\r\n",
    "bar2 = sns.barplot(x=\"Gender\",  y=\"profitPerPerson\",data=pgen,color=\"lightblue\")\r\n",
    "plt.title('Profit Gender wise for Pink cab company')\r\n",
    "# convert column to datetime pandas\r\n",
    "Data['Date of Travel'] = pd.to_datetime(Data['Date of Travel'])\r\n",
    "Data['Date of Travel'] = pd.to_datetime(Data['Date of Travel'],format='%Y%m%d')\r\n",
    "Data['year'] = pd.DatetimeIndex(Data['Date of Travel']).year\r\n",
    "\r\n",
    "# %%\r\n",
    "start = pd.to_datetime(\"31-1-2016\")\r\n",
    "end = pd.to_datetime(\"5-1-2018\")\r\n",
    "idx = pd.date_range(start, periods=365, end=\"5-1-2017\")\r\n",
    "Data.index = idx\r\n",
    "df_ts = Data.resample('W', how= 'max')\r\n",
    "ax = df_ts.plot(kind='bar', x=df_ts.index, stacked=True)\r\n",
    "# %%\r\n",
    "index = Data[\"Date of Travel\"]\r\n",
    "df = pd.DataFrame({'YellowCab Users':Yellowcab[\"Users\"],'PinkCab Users': Pinkcab[\"Users\"]},index=index )\r\n",
    "\r\n",
    "#%% sorting df according to date\r\n",
    "Data = Data.sort_values('Date of Travel').reset_index(drop=True)\r\n",
    "Data_i = Data.set_index('Date of Travel')\r\n",
    "Data_i\r\n",
    "# %%\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "08eaa630b6d6ef41e513d98fc14c4f08e71fd922f07d1ad918a8c85f5551350b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}